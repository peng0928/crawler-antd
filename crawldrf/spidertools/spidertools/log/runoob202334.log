2023-03-04 11:40:16 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 11:40:16 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 11:40:16 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 11:40:16 [scrapy.extensions.telnet] INFO: Telnet Password: 48758f793029aaa4
2023-03-04 11:40:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 11:40:16 [twisted] CRITICAL: Unhandled error in Deferred:
2023-03-04 11:40:16 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\spiders\__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 20, in __init__
    self.listing_value = self.eval(kwargs.get('listing_value'))
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 232, in eval
    obj = eval(urllib.parse.unquote(obj, 'utf-8')) if obj else obj
  File "<string>", line 1
    [//div[@id='content']/h1]
      ^
SyntaxError: invalid syntax
2023-03-04 11:40:50 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 11:40:50 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 11:40:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 11:40:50 [scrapy.extensions.telnet] INFO: Telnet Password: ba7ab2bad5e8b30c
2023-03-04 11:40:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 11:40:50 [twisted] CRITICAL: Unhandled error in Deferred:
2023-03-04 11:40:50 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\spiders\__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 25, in __init__
    self.listing_value = self.eval(kwargs.get('listing_value'))
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 242, in eval
    obj = eval(obj) if obj else obj
  File "<string>", line 1
    [//div[@id='content']/h1]
      ^
SyntaxError: invalid syntax
2023-03-04 11:41:32 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 11:41:32 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 11:41:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 11:41:32 [scrapy.extensions.telnet] INFO: Telnet Password: 7fbb12e622f03ebe
2023-03-04 11:41:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 11:41:32 [stdout] INFO: <class 'NoneType'>
2023-03-04 11:41:32 [stdout] INFO: None
2023-03-04 11:41:32 [stdout] INFO: <class 'str'>
2023-03-04 11:41:32 [stdout] INFO: [0]
2023-03-04 11:41:32 [stdout] INFO: <class 'str'>
2023-03-04 11:41:32 [stdout] INFO: [//div[@id='content']/h1]
2023-03-04 11:41:32 [twisted] CRITICAL: Unhandled error in Deferred:
2023-03-04 11:41:32 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\spiders\__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 25, in __init__
    self.listing_value = self.eval(kwargs.get('listing_value'))
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 243, in eval
    obj = eval(obj) if obj else obj
  File "<string>", line 1
    [//div[@id='content']/h1]
      ^
SyntaxError: invalid syntax
2023-03-04 11:43:45 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 11:43:45 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 11:43:45 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 11:43:45 [scrapy.extensions.telnet] INFO: Telnet Password: 0c3c79afde9a296b
2023-03-04 11:43:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 11:43:45 [twisted] CRITICAL: Unhandled error in Deferred:
2023-03-04 11:43:45 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\spiders\__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 23, in __init__
    'listing_value'), '==================================='))
TypeError: type() takes 1 or 3 arguments
2023-03-04 11:44:24 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 11:44:24 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 11:44:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 11:44:24 [scrapy.extensions.telnet] INFO: Telnet Password: f2624772387b7c05
2023-03-04 11:44:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 11:44:24 [stdout] INFO: [//div[@id='content']/h1]
2023-03-04 11:44:24 [stdout] INFO: <class 'str'>
2023-03-04 11:44:24 [stdout] INFO: ===================================
2023-03-04 11:44:24 [stdout] INFO: <class 'NoneType'>
2023-03-04 11:44:24 [stdout] INFO: None
2023-03-04 11:44:24 [stdout] INFO: <class 'str'>
2023-03-04 11:44:24 [stdout] INFO: [0]
2023-03-04 11:44:24 [stdout] INFO: <class 'str'>
2023-03-04 11:44:24 [stdout] INFO: [//div[@id='content']/h1]
2023-03-04 11:44:24 [twisted] CRITICAL: Unhandled error in Deferred:
2023-03-04 11:44:24 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\spiders\__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 27, in __init__
    self.listing_value = self.eval(kwargs.get('listing_value'))
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 245, in eval
    obj = eval(obj) if obj else obj
  File "<string>", line 1
    [//div[@id='content']/h1]
      ^
SyntaxError: invalid syntax
2023-03-04 11:44:58 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 11:44:58 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 11:44:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 11:44:58 [scrapy.extensions.telnet] INFO: Telnet Password: 500fb178464aedcb
2023-03-04 11:44:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 11:44:58 [stdout] INFO: [//div[@id='content']/h1]
2023-03-04 11:44:58 [stdout] INFO: <class 'str'>
2023-03-04 11:44:58 [stdout] INFO: ===================================
2023-03-04 11:44:58 [stdout] INFO: <class 'NoneType'>
2023-03-04 11:44:58 [stdout] INFO: None
2023-03-04 11:44:58 [stdout] INFO: <class 'str'>
2023-03-04 11:44:58 [stdout] INFO: [0]
2023-03-04 11:44:58 [stdout] INFO: <class 'str'>
2023-03-04 11:44:58 [stdout] INFO: [//div[@id='content']/h1]
2023-03-04 11:44:58 [twisted] CRITICAL: Unhandled error in Deferred:
2023-03-04 11:44:58 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\spiders\__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 27, in __init__
    self.listing_value = self.eval(kwargs.get('listing_value'))
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 245, in eval
    obj = eval(obj) if obj else obj
  File "<string>", line 1
    [//div[@id='content']/h1]
      ^
SyntaxError: invalid syntax
2023-03-04 11:45:44 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 11:45:44 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 11:45:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 11:45:44 [scrapy.extensions.telnet] INFO: Telnet Password: b92f2e10e054ac71
2023-03-04 11:45:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 11:45:44 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_name': '[0]', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': "['']"}
2023-03-04 11:45:44 [stdout] INFO: ===================================
2023-03-04 11:45:44 [stdout] INFO: <class 'NoneType'>
2023-03-04 11:45:44 [stdout] INFO: None
2023-03-04 11:45:44 [stdout] INFO: <class 'str'>
2023-03-04 11:45:44 [stdout] INFO: [0]
2023-03-04 11:45:44 [stdout] INFO: <class 'str'>
2023-03-04 11:45:44 [stdout] INFO: [//div[@id='content']/h1]
2023-03-04 11:45:44 [twisted] CRITICAL: Unhandled error in Deferred:
2023-03-04 11:45:44 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\spiders\__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 26, in __init__
    self.listing_value = self.eval(kwargs.get('listing_value'))
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 244, in eval
    obj = eval(obj) if obj else obj
  File "<string>", line 1
    [//div[@id='content']/h1]
      ^
SyntaxError: invalid syntax
2023-03-04 11:48:14 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 11:48:14 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 11:48:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 11:48:14 [scrapy.extensions.telnet] INFO: Telnet Password: d3a2fc52b38a8797
2023-03-04 11:48:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 11:48:14 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_name': '[0]', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[]'}
2023-03-04 11:48:14 [stdout] INFO: ===================================
2023-03-04 11:48:14 [stdout] INFO: <class 'NoneType'>
2023-03-04 11:48:14 [stdout] INFO: None
2023-03-04 11:48:14 [stdout] INFO: <class 'str'>
2023-03-04 11:48:14 [stdout] INFO: [0]
2023-03-04 11:48:14 [stdout] INFO: <class 'str'>
2023-03-04 11:48:14 [stdout] INFO: [//div[@id='content']/h1]
2023-03-04 11:48:14 [twisted] CRITICAL: Unhandled error in Deferred:
2023-03-04 11:48:14 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\spiders\__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 26, in __init__
    self.listing_value = self.eval(kwargs.get('listing_value'))
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 244, in eval
    obj = eval(obj) if obj else obj
  File "<string>", line 1
    [//div[@id='content']/h1]
      ^
SyntaxError: invalid syntax
2023-03-04 12:45:43 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:45:43 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:45:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:45:43 [scrapy.extensions.telnet] INFO: Telnet Password: 5114e468f46dedf7
2023-03-04 12:45:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:45:43 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_name': '[0]', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[1]'}
2023-03-04 12:45:43 [stdout] INFO: ===================================
2023-03-04 12:45:43 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:45:43 [stdout] INFO: None
2023-03-04 12:45:43 [stdout] INFO: <class 'str'>
2023-03-04 12:45:43 [stdout] INFO: [0]
2023-03-04 12:45:43 [stdout] INFO: <class 'str'>
2023-03-04 12:45:43 [stdout] INFO: [//div[@id='content']/h1]
2023-03-04 12:45:43 [twisted] CRITICAL: Unhandled error in Deferred:
2023-03-04 12:45:43 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\spiders\__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 26, in __init__
    self.listing_value = self.eval(kwargs.get('listing_value'))
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 244, in eval
    obj = eval(obj) if obj else obj
  File "<string>", line 1
    [//div[@id='content']/h1]
      ^
SyntaxError: invalid syntax
2023-03-04 12:45:51 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:45:51 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:45:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:45:52 [scrapy.extensions.telnet] INFO: Telnet Password: 6ebd43af1bceeb02
2023-03-04 12:45:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:45:52 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_name': '[0]', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[1]'}
2023-03-04 12:45:52 [stdout] INFO: ===================================
2023-03-04 12:45:52 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:45:52 [stdout] INFO: None
2023-03-04 12:45:52 [stdout] INFO: <class 'str'>
2023-03-04 12:45:52 [stdout] INFO: [0]
2023-03-04 12:45:52 [stdout] INFO: <class 'str'>
2023-03-04 12:45:52 [stdout] INFO: [//div[@id='content']/h1]
2023-03-04 12:45:52 [twisted] CRITICAL: Unhandled error in Deferred:
2023-03-04 12:45:52 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\spiders\__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 26, in __init__
    self.listing_value = self.eval(kwargs.get('listing_value'))
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 244, in eval
    obj = eval(obj) if obj else obj
  File "<string>", line 1
    [//div[@id='content']/h1]
      ^
SyntaxError: invalid syntax
2023-03-04 12:46:23 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:46:23 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:46:23 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:46:23 [scrapy.extensions.telnet] INFO: Telnet Password: 85d5fe51cf5eaa92
2023-03-04 12:46:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:46:23 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html'}
2023-03-04 12:46:23 [stdout] INFO: ===================================
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:23 [stdout] INFO: None
2023-03-04 12:46:23 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:46:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:46:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:46:24 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:46:24 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:46:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:46:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:46:24 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:46:24 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:46:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001995,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 46, 24, 410149),
 'log_count/ERROR': 1,
 'log_count/INFO': 37,
 'start_time': datetime.datetime(2023, 3, 4, 4, 46, 24, 408154)}
2023-03-04 12:46:24 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:46:30 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:46:30 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:46:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:46:30 [scrapy.extensions.telnet] INFO: Telnet Password: d74e97dbe66fbae1
2023-03-04 12:46:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:46:30 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_name': '[0]', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[1]'}
2023-03-04 12:46:30 [stdout] INFO: ===================================
2023-03-04 12:46:30 [stdout] INFO: <class 'NoneType'>
2023-03-04 12:46:30 [stdout] INFO: None
2023-03-04 12:46:30 [stdout] INFO: <class 'str'>
2023-03-04 12:46:30 [stdout] INFO: [0]
2023-03-04 12:46:30 [stdout] INFO: <class 'str'>
2023-03-04 12:46:30 [stdout] INFO: [//div[@id='content']/h1]
2023-03-04 12:46:30 [twisted] CRITICAL: Unhandled error in Deferred:
2023-03-04 12:46:30 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "d:\python3.7.7\lib\site-packages\scrapy\spiders\__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 26, in __init__
    self.listing_value = self.eval(kwargs.get('listing_value'))
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 244, in eval
    obj = eval(obj) if obj else obj
  File "<string>", line 1
    [//div[@id='content']/h1]
      ^
SyntaxError: invalid syntax
2023-03-04 12:47:17 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:47:17 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:47:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:47:17 [scrapy.extensions.telnet] INFO: Telnet Password: 63982b1ea8a72aa3
2023-03-04 12:47:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:47:17 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_name': '[0]', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[1]'}
2023-03-04 12:47:17 [stdout] INFO: ===================================
2023-03-04 12:47:17 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:47:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:47:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:47:17 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:47:17 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:47:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:47:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:47:17 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:47:17 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:47:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001996,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 47, 17, 696543),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 47, 17, 694547)}
2023-03-04 12:47:17 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:47:21 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:47:21 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:47:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:47:21 [scrapy.extensions.telnet] INFO: Telnet Password: 2b10ce46b31f4364
2023-03-04 12:47:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:47:21 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_name': '[0]', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[1]'}
2023-03-04 12:47:21 [stdout] INFO: ===================================
2023-03-04 12:47:21 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:47:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:47:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:47:22 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:47:22 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:47:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:47:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:47:22 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:47:22 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:47:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.002028,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 47, 22, 287782),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 47, 22, 285754)}
2023-03-04 12:47:22 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:47:28 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:47:28 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:47:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:47:28 [scrapy.extensions.telnet] INFO: Telnet Password: 6b3ce3b38b665a42
2023-03-04 12:47:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:47:28 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_name': '[0]', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[]'}
2023-03-04 12:47:28 [stdout] INFO: ===================================
2023-03-04 12:47:28 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:47:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:47:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:47:29 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:47:29 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:47:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:47:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:47:29 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:47:29 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:47:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001994,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 47, 29, 126022),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 47, 29, 124028)}
2023-03-04 12:47:29 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:47:33 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:47:33 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:47:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:47:33 [scrapy.extensions.telnet] INFO: Telnet Password: 098610bcfc48a6a5
2023-03-04 12:47:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:47:33 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_name': '[0]', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[]'}
2023-03-04 12:47:33 [stdout] INFO: ===================================
2023-03-04 12:47:33 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:47:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:47:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:47:33 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:47:33 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:47:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:47:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:47:33 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:47:33 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:47:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001995,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 47, 33, 952024),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 47, 33, 950029)}
2023-03-04 12:47:33 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:47:37 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:47:37 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:47:37 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:47:37 [scrapy.extensions.telnet] INFO: Telnet Password: 19d925ed6056ee80
2023-03-04 12:47:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:47:37 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_name': '[0]', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[]'}
2023-03-04 12:47:37 [stdout] INFO: ===================================
2023-03-04 12:47:37 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:47:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:47:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:47:37 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:47:37 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:47:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:47:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:47:37 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:47:37 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:47:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001993,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 47, 37, 733623),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 47, 37, 731630)}
2023-03-04 12:47:37 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:48:09 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:48:09 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:48:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:48:09 [scrapy.extensions.telnet] INFO: Telnet Password: 8c4a1a7e0813026e
2023-03-04 12:48:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:48:09 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[]'}
2023-03-04 12:48:09 [stdout] INFO: ===================================
2023-03-04 12:48:09 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:48:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:48:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:48:10 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:48:10 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:48:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:48:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:48:10 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:48:10 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:48:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001995,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 48, 10, 424158),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 48, 10, 422163)}
2023-03-04 12:48:10 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:48:30 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:48:30 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:48:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:48:30 [scrapy.extensions.telnet] INFO: Telnet Password: 2e19d384e31b8924
2023-03-04 12:48:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:48:30 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0'}
2023-03-04 12:48:30 [stdout] INFO: ===================================
2023-03-04 12:48:30 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:48:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:48:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:48:31 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:48:31 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:48:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:48:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:48:31 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:48:31 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:48:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.002993,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 48, 31, 347466),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 48, 31, 344473)}
2023-03-04 12:48:31 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:48:45 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:48:45 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:48:45 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:48:45 [scrapy.extensions.telnet] INFO: Telnet Password: 1d69fb4b49aea4f4
2023-03-04 12:48:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:48:45 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html'}
2023-03-04 12:48:45 [stdout] INFO: ===================================
2023-03-04 12:48:45 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:48:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:48:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:48:45 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:48:45 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:48:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:48:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:48:45 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:48:45 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:48:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001995,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 48, 45, 760095),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 48, 45, 758100)}
2023-03-04 12:48:45 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:48:58 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:48:58 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:48:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:48:58 [scrapy.extensions.telnet] INFO: Telnet Password: e7c22a85d851c357
2023-03-04 12:48:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:48:58 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0'}
2023-03-04 12:48:58 [stdout] INFO: ===================================
2023-03-04 12:48:58 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:48:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:48:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:48:58 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:48:58 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:48:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:48:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:48:58 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:48:58 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:48:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001995,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 48, 58, 967506),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 48, 58, 965511)}
2023-03-04 12:48:58 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:49:21 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:49:21 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:49:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:49:21 [scrapy.extensions.telnet] INFO: Telnet Password: af538b32723d1bef
2023-03-04 12:49:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:49:21 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[]'}
2023-03-04 12:49:21 [stdout] INFO: ===================================
2023-03-04 12:49:21 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:49:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:49:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:49:21 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:49:21 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:49:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:49:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:49:21 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:49:21 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:49:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.002992,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 49, 21, 757430),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 49, 21, 754438)}
2023-03-04 12:49:21 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:49:25 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:49:25 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:49:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:49:25 [scrapy.extensions.telnet] INFO: Telnet Password: cf16b9172124ba3b
2023-03-04 12:49:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:49:25 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0', 'listing_value': "[//div[@id='content']/h1]", 'listing_filter': '[]'}
2023-03-04 12:49:25 [stdout] INFO: ===================================
2023-03-04 12:49:25 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:49:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:49:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:49:25 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:49:25 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:49:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:49:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:49:26 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:49:26 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:49:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001995,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 49, 26, 19904),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 49, 26, 17909)}
2023-03-04 12:49:26 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:49:36 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:49:36 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:49:36 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:49:36 [scrapy.extensions.telnet] INFO: Telnet Password: f9640acb905e6a11
2023-03-04 12:49:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:49:36 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0'}
2023-03-04 12:49:36 [stdout] INFO: ===================================
2023-03-04 12:49:36 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:49:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:49:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:49:37 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:49:37 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:49:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:49:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:49:37 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:49:37 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:49:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001959,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 49, 37, 221703),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 49, 37, 219744)}
2023-03-04 12:49:37 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:49:47 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:49:47 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:49:47 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:49:47 [scrapy.extensions.telnet] INFO: Telnet Password: 51e09d4cbdb303bb
2023-03-04 12:49:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:49:47 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html', 'host': 'runoob', 'spider': 'runoob', 'project': '0'}
2023-03-04 12:49:47 [stdout] INFO: ===================================
2023-03-04 12:49:47 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:49:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:49:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:49:47 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:49:47 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:49:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:49:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:49:47 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:49:47 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:49:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001992,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 49, 47, 940899),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 49, 47, 938907)}
2023-03-04 12:49:47 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:50:07 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:50:07 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:50:07 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:50:07 [scrapy.extensions.telnet] INFO: Telnet Password: 910e417a800b9046
2023-03-04 12:50:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:50:07 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html'}
2023-03-04 12:50:07 [stdout] INFO: ===================================
2023-03-04 12:50:07 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:50:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:50:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:50:08 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:50:08 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:50:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:50:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:50:08 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:50:08 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:50:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001995,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 50, 8, 345360),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 50, 8, 343365)}
2023-03-04 12:50:08 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:50:24 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:50:24 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:50:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:50:24 [scrapy.extensions.telnet] INFO: Telnet Password: e1107c32b04ce53b
2023-03-04 12:50:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:50:24 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html '}
2023-03-04 12:50:24 [stdout] INFO: ===================================
2023-03-04 12:50:24 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:50:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:50:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:50:24 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:50:24 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:50:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:50:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:50:24 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:50:24 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:50:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.002029,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 50, 24, 714721),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 50, 24, 712692)}
2023-03-04 12:50:24 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:50:34 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:50:34 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:50:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:50:34 [scrapy.extensions.telnet] INFO: Telnet Password: 96d4fba1d953c6cc
2023-03-04 12:50:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:50:34 [stdout] INFO: {'starturl': 'https://www.runoob.com/python3/python3-dictionary.html'}
2023-03-04 12:50:34 [stdout] INFO: ===================================
2023-03-04 12:50:34 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:50:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:50:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:50:35 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:50:35 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:50:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:50:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:50:35 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:50:35 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:50:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001995,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 50, 35, 389946),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'start_time': datetime.datetime(2023, 3, 4, 4, 50, 35, 387951)}
2023-03-04 12:50:35 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:50:52 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:50:52 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:50:52 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:50:52 [scrapy.extensions.telnet] INFO: Telnet Password: 32d8bee722599c06
2023-03-04 12:50:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:50:52 [stdout] INFO: ===================================
2023-03-04 12:50:52 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:50:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:50:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:50:53 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:50:53 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:50:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:50:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:50:53 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:50:53 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:50:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001995,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 50, 53, 298492),
 'log_count/ERROR': 1,
 'log_count/INFO': 12,
 'start_time': datetime.datetime(2023, 3, 4, 4, 50, 53, 296497)}
2023-03-04 12:50:53 [scrapy.core.engine] INFO: Spider closed (finished)
2023-03-04 12:51:38 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: spidertools)
2023-03-04 12:51:38 [scrapy.utils.log] INFO: Versions: lxml 4.9.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform Windows-10-10.0.22000-SP0
2023-03-04 12:51:38 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spidertools',
 'COOKIES_ENABLED': False,
 'LOG_FILE': 'log/runoob202334.log',
 'LOG_LEVEL': 'INFO',
 'LOG_STDOUT': 'true',
 'NEWSPIDER_MODULE': 'spidertools.spiders',
 'SPIDER_MODULES': ['spidertools.spiders']}
2023-03-04 12:51:38 [scrapy.extensions.telnet] INFO: Telnet Password: 8ef70f11f2ee1bb6
2023-03-04 12:51:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-03-04 12:51:38 [stdout] INFO: ===================================
2023-03-04 12:51:38 [stdout] INFO: {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8,application/json,', 'Accept-Language': 'en,zh-CN,zh;q=0.9,en;q=0.8'}
2023-03-04 12:51:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spidertools.PenrMiddlewares.Middleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-03-04 12:51:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-03-04 12:51:38 [scrapy.middleware] INFO: Enabled item pipelines:
['spidertools.pipelines.SpidertoolsPipeline']
2023-03-04 12:51:38 [scrapy.core.engine] INFO: Spider opened
2023-03-04 12:51:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-03-04 12:51:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-03-04 12:51:38 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "d:\python3.7.7\lib\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "E:\桌面\python文件夹1\antd\crawler-antd\crawldrf\spidertools\spidertools\spiders\spider.py", line 58, in start_requests
    self.listing_url = self.listing_url[0].split('\r\n')
TypeError: 'NoneType' object is not subscriptable
2023-03-04 12:51:38 [scrapy.core.engine] INFO: Closing spider (finished)
2023-03-04 12:51:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001995,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 3, 4, 4, 51, 38, 542875),
 'log_count/ERROR': 1,
 'log_count/INFO': 12,
 'start_time': datetime.datetime(2023, 3, 4, 4, 51, 38, 540880)}
2023-03-04 12:51:38 [scrapy.core.engine] INFO: Spider closed (finished)
